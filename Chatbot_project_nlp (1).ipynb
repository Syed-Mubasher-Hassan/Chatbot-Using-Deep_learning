{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzUHWxmVMt27"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM,GRU, Embedding,Dropout, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0sIovpdBhT7"
      },
      "outputs": [],
      "source": [
        "# Load the JSON dataset\n",
        "\n",
        "with open('/content/drive/MyDrive/train.json') as file:\n",
        "    data = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hu8EafDubdy3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "training_sentences = []  # Agent 1' and 2 messages\n",
        "training_labels = []     # Sentiments\n",
        "responses = []           # Agent 2's responses\n",
        "labels = []              # Unique sentiment labels\n",
        "\n",
        "for message_id, message_data in data.items():\n",
        "    for content in message_data['content']:\n",
        "        agent_message = content['message']\n",
        "        sentiment = content['sentiment']\n",
        "        agent = content['agent']\n",
        "        training_sentences.append(agent_message)\n",
        "        training_labels.append(sentiment)\n",
        "\n",
        "        if agent == 'agent_2':\n",
        "            responses.append(agent_message)\n",
        "\n",
        "        # Check for unique labels\n",
        "        if sentiment not in labels:\n",
        "            labels.append(sentiment)\n",
        "num_classes = len(labels)\n",
        "\n",
        "# Now you have training sentences (Agent 1's messages), labels (sentiments), responses (Agent 2's messages), and unique labels in the 'labels' list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOGWJKbaNAdr",
        "outputId": "cf495b07-3edf-443e-d998-6b182f469b56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n",
            "188378\n",
            "188378\n",
            "91174\n"
          ]
        }
      ],
      "source": [
        "print(len(labels))\n",
        "print(len(training_sentences))\n",
        "print(len(training_labels))\n",
        "print(len(responses))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jF-1rOjMND4A"
      },
      "outputs": [],
      "source": [
        "training_sentences=training_sentences[:60000]\n",
        "training_labels=training_labels[:60000]\n",
        "responses=responses[:60000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_CvHu1vNNtI"
      },
      "outputs": [],
      "source": [
        "lbl_encoder = LabelEncoder()\n",
        "lbl_encoder.fit(training_labels)\n",
        "training_labels = lbl_encoder.transform(training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhiijCXeNRoL"
      },
      "outputs": [],
      "source": [
        "vocab_size = 40000\n",
        "embedding_dim = 200\n",
        "max_len = 512\n",
        "oov_token = \"<OOV>\"\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtJiVGNcNcZX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and temporary data (combining validation and testing)\n",
        "training_sentences, temp_sentences, training_labels, temp_labels = train_test_split(\n",
        "    padded_sequences, training_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "# Split the temporary data into validation and testing\n",
        "validation_sentences, test_sentences, validation_labels, test_labels = train_test_split(\n",
        "    temp_sentences, temp_labels, test_size=0.1, random_state=42)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pjp7dISmNkoN",
        "outputId": "a3bbe5a8-1035-4e9e-b4f5-0c7fa584d21d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 512, 200)          8000000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 512, 128)          168448    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512, 128)          0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 512, 256)          394240    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512, 256)          0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 512)               1574912   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 2056      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10270984 (39.18 MB)\n",
            "Trainable params: 10270984 (39.18 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
        "model.add(LSTM(128, return_sequences=True))  # You can adjust the number of LSTM units as needed\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(512))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWYAR3-1OCqO",
        "outputId": "55a62552-4bd8-4333-ac0f-2ee09748f660"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1313/1313 [==============================] - 228s 164ms/step - loss: 1.3705 - accuracy: 0.4389 - val_loss: 1.3290 - val_accuracy: 0.4539\n",
            "Epoch 2/5\n",
            "1313/1313 [==============================] - 204s 156ms/step - loss: 1.2528 - accuracy: 0.5065 - val_loss: 1.3099 - val_accuracy: 0.4757\n",
            "Epoch 3/5\n",
            "1313/1313 [==============================] - 207s 158ms/step - loss: 1.1154 - accuracy: 0.5768 - val_loss: 1.3380 - val_accuracy: 0.4589\n",
            "Epoch 4/5\n",
            "1313/1313 [==============================] - 205s 156ms/step - loss: 0.9598 - accuracy: 0.6477 - val_loss: 1.4542 - val_accuracy: 0.4478\n",
            "Epoch 5/5\n",
            "1313/1313 [==============================] - 202s 154ms/step - loss: 0.8055 - accuracy: 0.7110 - val_loss: 1.6080 - val_accuracy: 0.4605\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    training_sentences, training_labels,\n",
        "    epochs=5,  # Adjust the number of epochs as needed\n",
        "    validation_data=(validation_sentences, validation_labels),\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xji-DeZgeoVX",
        "outputId": "2eda3379-2540-4b58-a240-50e0f15ee99d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 [==============================] - 3s 48ms/step - loss: 1.6313 - accuracy: 0.4589\n",
            "Test Accuracy: 45.89%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test data when you're ready\n",
        "test_loss, test_accuracy = model.evaluate(test_sentences, test_labels)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Jd0Am2knZIf",
        "outputId": "a79e69f1-418a-48f1-a082-7e5fdbcc3230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1313/1313 [==============================] - 62s 46ms/step\n",
            "Training Classification Report:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "Curious to dive deeper       0.00      0.00      0.00       168\n",
            "                 Happy       0.75      0.93      0.83     17780\n",
            "               Neutral       0.50      0.00      0.01       276\n",
            "             Surprised       0.00      0.00      0.00       231\n",
            "             Disgusted       0.75      0.67      0.71      6630\n",
            "                   Sad       0.86      0.68      0.76      9394\n",
            "               Fearful       0.48      0.65      0.55       614\n",
            "                 Angry       0.82      0.70      0.75      6907\n",
            "\n",
            "              accuracy                           0.77     42000\n",
            "             macro avg       0.52      0.45      0.45     42000\n",
            "          weighted avg       0.77      0.77      0.76     42000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Make predictions on the training data\n",
        "train_predictions = model.predict(training_sentences)\n",
        "\n",
        "# Convert the predictions from one-hot encoding to class labels\n",
        "train_predicted_labels = np.argmax(train_predictions, axis=1)\n",
        "\n",
        "# Generate a classification report for training data\n",
        "train_class_report = classification_report(training_labels, train_predicted_labels, target_names=labels)\n",
        "\n",
        "# Print the training classification report\n",
        "print(\"Training Classification Report:\\n\", train_class_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzXrViJimp31",
        "outputId": "0478aaf7-539a-4307-da42-8b9f61894d62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57/57 [==============================] - 3s 46ms/step\n",
            "Classification Report:\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "Curious to dive deeper       0.00      0.00      0.00         9\n",
            "                 Happy       0.53      0.72      0.61       752\n",
            "               Neutral       0.00      0.00      0.00        11\n",
            "             Surprised       0.00      0.00      0.00        16\n",
            "             Disgusted       0.33      0.30      0.31       275\n",
            "                   Sad       0.42      0.31      0.36       419\n",
            "               Fearful       0.20      0.12      0.15        24\n",
            "                 Angry       0.32      0.24      0.28       294\n",
            "\n",
            "              accuracy                           0.46      1800\n",
            "             macro avg       0.23      0.21      0.21      1800\n",
            "          weighted avg       0.43      0.46      0.43      1800\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model.predict(test_sentences)\n",
        "\n",
        "# Convert the predictions from one-hot encoding to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Generate a classification report\n",
        "class_report = classification_report(test_labels, predicted_labels, target_names=labels)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\\n\", class_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJ6jZTonOM_h"
      },
      "outputs": [],
      "source": [
        "\n",
        "# to save the trained model\n",
        "model.save(\"chat_model\")\n",
        "\n",
        "import pickle\n",
        "\n",
        "# to save the fitted tokenizer\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# to save the fitted label encoder\n",
        "with open('label_encoder.pickle', 'wb') as ecn_file:\n",
        "    pickle.dump(lbl_encoder, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGvYZnPOuYbd",
        "outputId": "6cdc083e-ea55-406f-ecfe-2f4714ec1ef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n"
          ]
        }
      ],
      "source": [
        "pip install colorama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nEz2pCypc2V",
        "outputId": "aa6a945f-1f5f-4a3a-f07a-a95c1529fd5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start messaging with the bot (type quit to stop)!\n",
            "User: hello\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "ChatBot: Have a good one!\n",
            "User: i am huge fun of\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "ChatBot: yup, the plot is dumb and they ruined luke as a character, I also don't know why they translated star wars into navajo in 2013 that seems like a limited audience haha\n",
            "User: mircrosoft\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "ChatBot: That was kind of them.  Have you followed Pokemon?  They have enough episodes to last for a couple years if you watch an episode every day.  They have 750 in fact!\n",
            "User: how are you\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "ChatBot: She was not at fault.  In general I would not want to buy my kids fancy shoes or cars that would attract attention from bad people.\n",
            "User: She was not at fault\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "ChatBot: Nokie started out playing a Fender Telecaster then switched to a Mosrite.  Fender is a prominent guitar maker.  I have not heard of Mosrite.  Have you?\n",
            "User: quit\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import colorama\n",
        "colorama.init()\n",
        "from colorama import Fore, Style, Back\n",
        "\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "def chat():\n",
        "    # load trained model\n",
        "    model = keras.models.load_model('chat_model')\n",
        "\n",
        "    # load tokenizer object\n",
        "    with open('tokenizer.pickle', 'rb') as handle:\n",
        "        tokenizer = pickle.load(handle)\n",
        "\n",
        "    # load label encoder object\n",
        "    with open('label_encoder.pickle', 'rb') as enc:\n",
        "        lbl_encoder = pickle.load(enc)\n",
        "\n",
        "    # parameters\n",
        "    max_len =512\n",
        "\n",
        "    while True:\n",
        "        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
        "        inp = input()\n",
        "        if inp.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),\n",
        "                                             truncating='post', maxlen=max_len))\n",
        "        sentiment = lbl_encoder.inverse_transform([np.argmax(result)])\n",
        "\n",
        "        # Initialize a variable to track whether a response has been generated\n",
        "        response_generated = False\n",
        "\n",
        "        for id, message_data in data.items():\n",
        "            for i in message_data['content']:\n",
        "                if i['sentiment'] == sentiment:\n",
        "                    print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL, np.random.choice(responses))\n",
        "                    response_generated = True\n",
        "                    break  # Exit the inner loop once a response is generated\n",
        "\n",
        "            if response_generated:\n",
        "                break  # Exit the outer loop if a response is generated\n",
        "\n",
        "          # print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL,random.choice(responses))\n",
        "\n",
        "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n",
        "chat()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXi__CRCuThk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}